{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepchem_experiments_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uzuhzQteh6Lt",
        "Ntd-JgF6dfAF",
        "PRiOW2Qtdjxt",
        "CnBREfovdZNe",
        "AWAxjyqH0OA6",
        "EVmV0dC60X0H",
        "FdMYqUibCEkz",
        "5_ZO74t1mFtj",
        "ULG1CrvZBwIV",
        "PCaDD2JYwkVL",
        "KJGwzpF4c7Tu",
        "AWY10vJ9Sf3A",
        "YaXcLxFCME__",
        "rTG118GJ9czB",
        "MVt0kHxFLGeg",
        "j9qugXLbLKSa",
        "Avqm1NpoLO2F"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL0RsXoHiK-m"
      },
      "source": [
        "### **Drug Discovery**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzuhzQteh6Lt"
      },
      "source": [
        "## Mount Google drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7oiQ-u_1td6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntd-JgF6dfAF"
      },
      "source": [
        "## Package installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnni4XBKKt2W"
      },
      "source": [
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-py37_4.8.3-Linux-x86_64.sh -b -f -p /usr/local\n",
        "#!time conda install -q -y -c conda-forge rdkit\n",
        "!time conda install -c rdkit rdkit\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB-6AKYKL2wh"
      },
      "source": [
        "!pip install --pre deepchem #\n",
        "!pip install dgl-cu110\n",
        "!pip install dgllife"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGZc3HdLitKz"
      },
      "source": [
        "!pip install xgboost\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRiOW2Qtdjxt"
      },
      "source": [
        "## Import librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rrhw_-Nldos6"
      },
      "source": [
        "import deepchem as dc\n",
        "from deepchem.molnet.preset_hyper_parameters import hps\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnBREfovdZNe"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QwXbN0XZg-v"
      },
      "source": [
        "def load_data(model, data):\n",
        "    \n",
        "    if model in [\"graphconv\", \"dag\"]:\n",
        "      featurizer = dc.feat.ConvMolFeaturizer()\n",
        "    elif model in [\"tf\", \"irv\", \"tf_robust\", \"kernelsvm\", \"rf\", \"logreg\", \"xgb\"]:\n",
        "      featurizer = dc.feat.CircularFingerprint()\n",
        "    elif model in [\"gat\", \"gcn\"]:\n",
        "      featurizer = dc.feat.MolGraphConvFeaturizer()\n",
        "    elif model == \"mpnn\":\n",
        "      featurizer = dc.feat.WeaveFeaturizer()\n",
        "    elif model == \"textcnn\":\n",
        "      featurizer = None\n",
        "\n",
        "    tasks = ['label']\n",
        "    loader = dc.data.CSVLoader(tasks=tasks, feature_field=\"smiles\",featurizer=featurizer)\n",
        "    dataset = loader.create_dataset(data)\n",
        "    transformer = None\n",
        "\n",
        "    return (dataset, [transformer])\n",
        "\n",
        "def load_split(model, train_data, test_data):\n",
        "    \n",
        "    train = None\n",
        "    test  = None\n",
        "    if model in [\"graphconv\", \"dag\"]:\n",
        "      featurizer = dc.feat.ConvMolFeaturizer()\n",
        "    elif model in [\"tf\", \"irv\", \"tf_robust\", \"kernelsvm\", \"rf\", \"logreg\"]:\n",
        "      featurizer = dc.feat.CircularFingerprint()\n",
        "    elif model in [\"gat\", \"gcn\"]:\n",
        "      featurizer = dc.feat.MolGraphConvFeaturizer()\n",
        "    elif model == \"mpnn\":\n",
        "      featurizer = dc.feat.WeaveFeaturizer()\n",
        "    elif model == \"textcnn\":\n",
        "      featurizer = None\n",
        "\n",
        "    \n",
        "    for inputfile in [train_data, test_data]:\n",
        "        \n",
        "        if inputfile != None:\n",
        "            \n",
        "            #print(inputfile)\n",
        "            tasks = ['label']\n",
        "            loader = dc.data.CSVLoader(tasks=tasks, feature_field=\"smiles\",featurizer=featurizer)\n",
        "            dataset = loader.create_dataset(inputfile)\n",
        "            transformer = None\n",
        "            #transformer = dc.trans.BalancingTransformer(dataset=dataset)\n",
        "            #dataset = transformer.transform(dataset)\n",
        "            \n",
        "            if inputfile == train_data:\n",
        "                train = dataset\n",
        "            else:\n",
        "                test = dataset\n",
        "\n",
        "    return (train, test, [transformer])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHobkiRxqdhB"
      },
      "source": [
        "data = \"/mydrive/drug_discovery/heterogene.csv\"\n",
        "dataset, transformers = load_data(\"graphconv\", data)\n",
        "splitter = dc.splits.RandomSplitter()\n",
        "train_dataset, val_dataset, test_dataset = splitter.train_valid_test_split(dataset, frac_train = 0.8, frac_valid = 0.1, frac_test = 0.1, seed=123)\n",
        "#pred_data = \"/mydrive/drug_discovery/gcnsmiles.csv\"\n",
        "#test_dataset, transformers = load_data(\"gcn\", pred_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v97zy3OIZttm",
        "outputId": "5d3c1686-8fa3-479d-c6a9-76dc3087647d"
      },
      "source": [
        "#print(\"Dataset size  : \",train_dataset.X.shape[0] + test_dataset.X.shape[0])\n",
        "print(\"All data size : \",dataset.X.shape[0])\n",
        "print(\"Valset size : \",val_dataset.X.shape[0])\n",
        "print(\"Testset size  : \",test_dataset.X.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All data size :  2601\n",
            "Valset size :  260\n",
            "Testset size  :  261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRwb4DCSdJz0"
      },
      "source": [
        "# Fit Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWAxjyqH0OA6"
      },
      "source": [
        "## benchmark classification"
      ]
    },

